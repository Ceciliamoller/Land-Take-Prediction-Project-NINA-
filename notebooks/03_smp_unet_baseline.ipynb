{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818a16e2",
   "metadata": {},
   "source": [
    "# U-Net Baseline\n",
    "\n",
    "Fair comparison setup: shared splits, patch size (64x64), normalization, and random seeds with FCEF baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfa0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "if 'src.config' in sys.modules:\n",
    "    importlib.reload(sys.modules['src.config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cc6e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/.venv/lib/python3.12/site-packages/matplotlib/__init__.py:1299\u001b[39m\n\u001b[32m   1295\u001b[39m     rcParams[\u001b[33m'\u001b[39m\u001b[33mbackend_fallback\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m'\u001b[39m\u001b[33mMPLBACKEND\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     \u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = os.environ.get(\u001b[33m'\u001b[39m\u001b[33mMPLBACKEND\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_backend\u001b[39m(*, auto_select=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1303\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1304\u001b[39m \u001b[33;03m    Return the name of the current backend.\u001b[39;00m\n\u001b[32m   1305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m \u001b[33;03m    matplotlib.use\u001b[39;00m\n\u001b[32m   1324\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/.venv/lib/python3.12/site-packages/matplotlib/__init__.py:772\u001b[39m, in \u001b[36mRcParams.__setitem__\u001b[39m\u001b[34m(self, key, val)\u001b[39m\n\u001b[32m    770\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m     cval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/.venv/lib/python3.12/site-packages/matplotlib/rcsetup.py:273\u001b[39m, in \u001b[36mvalidate_backend\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_backend\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m _auto_backend_sentinel \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_valid_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/.venv/lib/python3.12/site-packages/matplotlib/backends/registry.py:244\u001b[39m, in \u001b[36mBackendRegistry.is_valid_backend\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Only load entry points if really need to and not already done so.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_entry_points_loaded\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend_to_gui_framework:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/.venv/lib/python3.12/site-packages/matplotlib/backends/registry.py:116\u001b[39m, in \u001b[36mBackendRegistry._ensure_entry_points_loaded\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ensure_entry_points_loaded\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Load entry points, if they have not already been loaded.\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._loaded_entry_points:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         entries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_entry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_and_store_entry_points(entries)\n\u001b[32m    118\u001b[39m         \u001b[38;5;28mself\u001b[39m._loaded_entry_points = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/.venv/lib/python3.12/site-packages/matplotlib/backends/registry.py:136\u001b[39m, in \u001b[36mBackendRegistry._read_entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_entry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# Read entry points of modules that self-advertise as Matplotlib backends.\u001b[39;00m\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Expects entry points like this one from matplotlib-inline (in pyproject.toml\u001b[39;00m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# format):\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m#   [project.entry-points.\"matplotlib.backend\"]\u001b[39;00m\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m#   inline = \"matplotlib_inline.backend_inline\"\u001b[39;00m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mim\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     entry_points = \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmatplotlib.backend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     entries = [(entry.name, entry.value) \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entry_points]\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# For backward compatibility, if matplotlib-inline and/or ipympl are installed\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# but too old to include entry points, create them. Do not import ipympl\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# directly as this calls matplotlib.use() whilst in this function.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/metadata/__init__.py:913\u001b[39m, in \u001b[36mentry_points\u001b[39m\u001b[34m(**params)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m    903\u001b[39m \n\u001b[32m    904\u001b[39m \u001b[33;03mPass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    908\u001b[39m \u001b[33;03m:return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m    909\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    910\u001b[39m eps = itertools.chain.from_iterable(\n\u001b[32m    911\u001b[39m     dist.entry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m    912\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEntryPoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m.select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/metadata/__init__.py:911\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(**params) -> EntryPoints:\n\u001b[32m    902\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m    903\u001b[39m \n\u001b[32m    904\u001b[39m \u001b[33;03m    Pass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    908\u001b[39m \u001b[33;03m    :return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m    909\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    910\u001b[39m     eps = itertools.chain.from_iterable(\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m         \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m    912\u001b[39m     )\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints(eps).select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/metadata/__init__.py:471\u001b[39m, in \u001b[36mDistribution.entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints._from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mentry_points.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/metadata/__init__.py:819\u001b[39m, in \u001b[36mPathDistribution.read_text\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[32m    812\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[32m    813\u001b[39m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[32m    814\u001b[39m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    817\u001b[39m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[32m    818\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pathlib.py:1028\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors)\u001b[39m\n\u001b[32m   1026\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.open(mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=encoding, errors=errors) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = Path().resolve().parents[0]\n",
    "sys.path.append(str(root))\n",
    "\n",
    "from src.config import SENTINEL_DIR, MASK_DIR\n",
    "from src.data.sentinel_habloss_dataset import SentinelHablossPatchDataset\n",
    "from src.data.splits import get_splits, get_ref_ids_from_directory\n",
    "from src.data.transform import compute_normalization_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7961bc",
   "metadata": {},
   "source": [
    "## Set Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"All random seeds set to {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfdb6c",
   "metadata": {},
   "source": [
    "## Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78362859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df934e",
   "metadata": {},
   "source": [
    "## Train/Val/Test Splits\n",
    "\n",
    "Shared splits with FCEF: 70/15/15, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba28c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentinel files found: 34\n",
      "\n",
      "Train files: 23 (~68%)\n",
      "Val files: 5 (~15%)\n",
      "Test files: 6 (~18%)\n",
      "\n",
      "Example train file: a16-15317118163363_45-7859705066069_RGBNIRRSWIRQ_Mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "all_ref_ids = get_ref_ids_from_directory(SENTINEL_DIR)\n",
    "print(f\"Total reference IDs found: {len(all_ref_ids)}\")\n",
    "\n",
    "train_ref_ids, val_ref_ids, test_ref_ids = get_splits(\n",
    "    all_ref_ids,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain tiles: {len(train_ref_ids)} (~{100*len(train_ref_ids)/len(all_ref_ids):.0f}%)\")\n",
    "print(f\"Val tiles: {len(val_ref_ids)} (~{100*len(val_ref_ids)/len(all_ref_ids):.0f}%)\")\n",
    "print(f\"Test tiles: {len(test_ref_ids)} (~{100*len(test_ref_ids)/len(all_ref_ids):.0f}%)\")\n",
    "print(f\"\\nExample train ID: {train_ref_ids[0]}\")\n",
    "print(f\"\\n✓ Using SHARED splits with FCEF baseline (random_state={RANDOM_SEED})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c01ae2",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "\n",
    "Shared normalization: scale by 10000 + mean/std standardization (training set only)\n",
    "Patch size: 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c9bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating per-channel mean and std from training data...\n",
      "Computed mean: 126 values\n",
      "Computed std: 126 values\n",
      "\n",
      "Training patches: 460 (from 23 files)\n",
      "Validation patches: 50 (from 5 files)\n",
      "Test patches: 60 (from 6 files)\n",
      "Number of input channels: 126\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE = 64\n",
    "\n",
    "temp_train_ds = SentinelHablossPatchDataset(\n",
    "    SENTINEL_DIR, MASK_DIR, \n",
    "    patch_size=PATCH_SIZE,\n",
    "    patches_per_image=5,\n",
    "    mean=None,\n",
    "    std=None, \n",
    "    augment=False,\n",
    "    ref_ids=train_ref_ids\n",
    ")\n",
    "\n",
    "print(\"Estimating per-channel mean and std from training data...\")\n",
    "mean, std = compute_normalization_stats(temp_train_ds, num_samples=2000)\n",
    "print(f\"✓ Computed normalization stats: {len(mean)} channels\")\n",
    "print(f\"  Mean (first 5): {[f'{m:.4f}' for m in mean[:5]]}\")\n",
    "print(f\"  Std (first 5): {[f'{s:.4f}' for s in std[:5]]}\")\n",
    "\n",
    "# Create actual datasets with shared normalization\n",
    "train_ds = SentinelHablossPatchDataset(\n",
    "    SENTINEL_DIR, MASK_DIR, \n",
    "    patch_size=PATCH_SIZE,\n",
    "    patches_per_image=20, \n",
    "    mean=mean, \n",
    "    std=std, \n",
    "    augment=True,\n",
    "    ref_ids=train_ref_ids\n",
    ")\n",
    "\n",
    "val_ds = SentinelHablossPatchDataset(\n",
    "    SENTINEL_DIR, MASK_DIR, \n",
    "    patch_size=PATCH_SIZE,\n",
    "    patches_per_image=10, \n",
    "    mean=mean, \n",
    "    std=std, \n",
    "    augment=False,\n",
    "    ref_ids=val_ref_ids\n",
    ")\n",
    "\n",
    "test_ds = SentinelHablossPatchDataset(\n",
    "    SENTINEL_DIR, MASK_DIR, \n",
    "    patch_size=PATCH_SIZE,\n",
    "    patches_per_image=10, \n",
    "    mean=mean, \n",
    "    std=std, \n",
    "    augment=False,\n",
    "    ref_ids=test_ref_ids\n",
    ")\n",
    "\n",
    "# Worker init function for reproducible shuffling\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_seed = RANDOM_SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# Create dataloaders with reproducible shuffling\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=8, \n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    generator=torch.Generator().manual_seed(RANDOM_SEED)\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\n✓ Datasets created with SHARED normalization and patch_size={PATCH_SIZE}\")\n",
    "print(f\"Training patches: {len(train_ds)} (from {len(train_ref_ids)} tiles)\")\n",
    "print(f\"Validation patches: {len(val_ds)} (from {len(val_ref_ids)} tiles)\")\n",
    "print(f\"Test patches: {len(test_ds)} (from {len(test_ref_ids)} tiles)\")\n",
    "print(f\"Number of input channels: {train_ds.num_bands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d474dca",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65607ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 126 input channels and moved to cpu\n"
     ]
    }
   ],
   "source": [
    "num_input_channels = train_ds.num_bands\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=126,\n",
    "    classes=2\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created with {num_input_channels} input channels and moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56722e",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36ccb4",
   "metadata": {},
   "source": [
    "## Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cbffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_binary(y_pred, y_true, positive_class=1):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix for binary classification.\n",
    "    y_pred, y_true: (B, H, W) with 0/1 labels\n",
    "    returns TP, FP, TN, FN as scalars\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred == positive_class)\n",
    "    y_true = (y_true == positive_class)\n",
    "\n",
    "    tp = (y_pred & y_true).sum().item()\n",
    "    fp = (y_pred & ~y_true).sum().item()\n",
    "    tn = (~y_pred & ~y_true).sum().item()\n",
    "    fn = (~y_pred & y_true).sum().item()\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def compute_metrics_from_confusion(tp, fp, tn, fn, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute metrics from confusion matrix values.\n",
    "    Returns: dict with accuracy, precision, recall, f1, iou\n",
    "    \"\"\"\n",
    "    accuracy  = (tp + tn) / (tp + tn + fp + fn + eps)\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall    = tp / (tp + fn + eps)\n",
    "    f1        = 2 * precision * recall / (precision + recall + eps)\n",
    "    iou       = tp / (tp + fp + fn + eps)  # IoU for the positive class\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"iou\": iou,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4490f93",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for imgs, masks in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use automatic mixed precision for faster training\n",
    "        with torch.amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "            logits = model(imgs)\n",
    "            loss = loss_fn(logits, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    sum_tp = sum_fp = sum_tn = sum_fn = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            with torch.amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                logits = model(imgs)\n",
    "                loss = loss_fn(logits, masks)\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            tp, fp, tn, fn = compute_confusion_binary(pred, masks, positive_class=1)\n",
    "            sum_tp += tp\n",
    "            sum_fp += fp\n",
    "            sum_tn += tn\n",
    "            sum_fn += fn\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    metrics = compute_metrics_from_confusion(sum_tp, sum_fp, sum_tn, sum_fn)\n",
    "    \n",
    "    return avg_loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f7459",
   "metadata": {},
   "source": [
    "## Initialize WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mceciliamoller\u001b[0m (\u001b[33mnina_prosjektoppgave\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/cecilia/Desktop/NTNU/Fordypningsprosjekt/Land-Take-Prediction-Project-NINA-/notebooks/wandb/run-20251127_132559-02mtgwgl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nina_prosjektoppgave/smp_unet/runs/02mtgwgl' target=\"_blank\">smart-butterfly-3</a></strong> to <a href='https://wandb.ai/nina_prosjektoppgave/smp_unet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nina_prosjektoppgave/smp_unet' target=\"_blank\">https://wandb.ai/nina_prosjektoppgave/smp_unet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nina_prosjektoppgave/smp_unet/runs/02mtgwgl' target=\"_blank\">https://wandb.ai/nina_prosjektoppgave/smp_unet/runs/02mtgwgl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"smp_unet\",\n",
    "    entity=\"nina_prosjektoppgave\",\n",
    "    config={\n",
    "        \"model\": \"Unet\",\n",
    "        \"encoder\": \"resnet34\",\n",
    "        \"encoder_weights\": \"imagenet\",\n",
    "        \"in_channels\": train_ds.num_bands,\n",
    "        \"classes\": 2,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 8,\n",
    "        \"patch_size\": PATCH_SIZE,\n",
    "        \"epochs\": 10,\n",
    "        \"train_patches_per_image\": 20,\n",
    "        \"val_patches_per_image\": 10,\n",
    "        \"test_patches_per_image\": 10,\n",
    "        \"train_ref_ids\": len(train_ref_ids),\n",
    "        \"val_ref_ids\": len(val_ref_ids),\n",
    "        \"test_ref_ids\": len(test_ref_ids),\n",
    "        \"augmentation\": True,\n",
    "        \"normalization\": \"scale_10000_plus_standardize\",\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"train_ratio\": 0.7,\n",
    "        \"val_ratio\": 0.15,\n",
    "        \"test_ratio\": 0.15,\n",
    "        \"fair_comparison\": \"shared_splits_normalization_patch_size_with_FCEF\",\n",
    "    },\n",
    ")\n",
    "\n",
    "wandb.watch(model, log=\"all\", log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a026d",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e70a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_examples(images, masks, preds, step, phase=\"train\"):\n",
    "    preds_class = preds.argmax(dim=1)\n",
    "    \n",
    "    rgb_imgs = images[:, :3, :, :].clone()\n",
    "    for i in range(3):\n",
    "        min_val = rgb_imgs[:, i, :, :].min()\n",
    "        max_val = rgb_imgs[:, i, :, :].max()\n",
    "        if max_val > min_val:\n",
    "            rgb_imgs[:, i, :, :] = (rgb_imgs[:, i, :, :] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    wandb_images = []\n",
    "    for i in range(min(4, images.size(0))):\n",
    "        wandb_images.append(\n",
    "            wandb.Image(\n",
    "                rgb_imgs[i].cpu(),\n",
    "                masks={\n",
    "                    \"ground_truth\": {\"mask_data\": masks[i].cpu().numpy(), \"class_labels\": {0: \"background\", 1: \"land-take\"}},\n",
    "                    \"prediction\": {\"mask_data\": preds_class[i].cpu().numpy(), \"class_labels\": {0: \"background\", 1: \"land-take\"}},\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    wandb.log({f\"{phase}_examples\": wandb_images}, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54068297",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py:1529\u001b[39m, in \u001b[36mLogger.info\u001b[39m\u001b[34m(self, msg, *args, **kwargs)\u001b[39m\n\u001b[32m   1526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isEnabledFor(DEBUG):\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28mself\u001b[39m._log(DEBUG, msg, args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, *args, **kwargs):\n\u001b[32m   1530\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[33;03m    Log 'msg % args' with severity 'INFO'.\u001b[39;00m\n\u001b[32m   1532\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1536\u001b[39m \u001b[33;03m    logger.info(\"Houston, we have a %s\", \"notable problem\", exc_info=True)\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isEnabledFor(INFO):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'rasterio._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1529, in info\n",
      "    def info(self, msg, *args, **kwargs):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_ious = []\n",
    "val_f1s = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train_one_epoch(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation with full metrics\n",
    "    val_loss, val_metrics = validate(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_ious.append(val_metrics['iou'])\n",
    "    val_f1s.append(val_metrics['f1'])\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_iou\": val_metrics['iou'],\n",
    "        \"val_f1\": val_metrics['f1'],\n",
    "        \"val_precision\": val_metrics['precision'],\n",
    "        \"val_recall\": val_metrics['recall'],\n",
    "        \"val_accuracy\": val_metrics['accuracy'],\n",
    "    })\n",
    "    \n",
    "    # Log example predictions every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_imgs, val_masks = next(iter(val_loader))\n",
    "            val_imgs = val_imgs.to(device)\n",
    "            val_preds = model(val_imgs)\n",
    "            log_examples(val_imgs, val_masks, val_preds, step=epoch + 1, phase=\"val\")\n",
    "    \n",
    "    # Print concise epoch summary\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}: \"\n",
    "        f\"train_loss={train_loss:.4f} \"\n",
    "        f\"val_loss={val_loss:.4f} | \"\n",
    "        f\"IoU={val_metrics['iou']:.4f} \"\n",
    "        f\"F1={val_metrics['f1']:.4f} \"\n",
    "        f\"Prec={val_metrics['precision']:.4f} \"\n",
    "        f\"Rec={val_metrics['recall']:.4f} \"\n",
    "        f\"Acc={val_metrics['accuracy']:.4f}\"\n",
    "    )\n",
    "\n",
    "# Finish WandB run\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"\\nTraining Complete!\")\n",
    "print(f\"Final Validation Metrics:\")\n",
    "print(f\"  Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"  IoU: {val_ious[-1]:.4f}\")\n",
    "print(f\"  F1: {val_f1s[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2409a74",
   "metadata": {},
   "source": [
    "## Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43459b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "axes[0].plot(epochs, train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs, val_losses, 'r-s', label='Validation Loss', linewidth=2, markersize=6)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: IoU\n",
    "axes[1].plot(epochs, val_ious, 'g-^', label='Validation IoU', linewidth=2, markersize=6)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('IoU', fontsize=12)\n",
    "axes[1].set_title('Validation IoU', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: F1 Score\n",
    "axes[2].plot(epochs, val_f1s, 'm-d', label='Validation F1', linewidth=2, markersize=6)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('F1 Score', fontsize=12)\n",
    "axes[2].set_title('Validation F1 Score', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Validation IoU: {val_ious[-1]:.4f}\")\n",
    "print(f\"Validation F1: {val_f1s[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11535c",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526362df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_metrics = validate(test_loader)\n",
    "\n",
    "print(f\"Test Set Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  IoU: {test_metrics['iou']:.4f}\")\n",
    "print(f\"  F1: {test_metrics['f1']:.4f}\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
