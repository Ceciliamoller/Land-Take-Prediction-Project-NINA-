{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190bb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add repo root\n",
    "root = Path().resolve().parents[0]\n",
    "sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1547d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emma\\Documents\\Land-Take-Prediction-Project-NINA-\\data\\raw\\Sentinel\\a26-040070508867_45-95719246129747_RGBNIRRSWIRQ_Mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.data.timeseries_dataset import TimeSeriesDataset\n",
    "from src.config import SENTINEL_DIR, MASK_DIR\n",
    "\n",
    "all_sentinel_files = list(SENTINEL_DIR.glob(\"*_RGBNIRRSWIRQ_Mosaic.tif\"))\n",
    "train_ids, val_ids = train_test_split(all_sentinel_files, test_size=0.1, random_state=0)\n",
    "\n",
    "print(train_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be11fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.transform import ComposeTS, NormalizeBy, RandomCropTS, CenterCropTS\n",
    "\n",
    "CROP = 64  # use 64 if your tiles are tiny; 128 or 256 only if your tiles are large enough\n",
    "\n",
    "train_transform = ComposeTS([\n",
    "    NormalizeBy(10000.0),\n",
    "    RandomCropTS(CROP),\n",
    "])\n",
    "\n",
    "val_transform = ComposeTS([\n",
    "    NormalizeBy(10000.0),\n",
    "    CenterCropTS(CROP),          # deterministic for validation\n",
    "])\n",
    "\n",
    "train_ds = TimeSeriesDataset(train_ids, sensor=\"sentinel\", slice_mode=\"first_half\", transform=train_transform)\n",
    "val_ds   = TimeSeriesDataset(val_ids,   sensor=\"sentinel\", slice_mode=\"first_half\", transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcb30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8314d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x, mask = next(iter(train_loader))\n",
    "print(torch.unique(mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939eed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any tiles with background (0)? True\n",
      "any tiles with change (>0)? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ds_raw = TimeSeriesDataset(train_ids, sensor=\"sentinel\", slice_mode=\"first_half\", transform=None)\n",
    "has_zero = False\n",
    "has_nonzero = False\n",
    "\n",
    "for i in range(len(ds_raw)):\n",
    "    _, m = ds_raw[i]\n",
    "    u = torch.unique(m)\n",
    "    if (u == 0).any():\n",
    "        has_zero = True\n",
    "    if (u > 0).any():\n",
    "        has_nonzero = True\n",
    "\n",
    "print(\"any tiles with background (0)?\", has_zero)\n",
    "print(\"any tiles with change (>0)?\", has_nonzero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c12270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([4, 7, 9, 64, 64])\n",
      "x range: 0.03660000115633011 0.5397499799728394\n",
      "mask shape: torch.Size([4, 64, 64])\n",
      "mask unique: tensor([1])\n",
      "any NaN in x: False\n",
      "any NaN in mask: False\n"
     ]
    }
   ],
   "source": [
    "x, mask = next(iter(train_loader))\n",
    "print(\"x shape:\", x.shape)              # (B, T, C, H, W)\n",
    "print(\"x range:\", x.min().item(), x.max().item())\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"mask unique:\", torch.unique(mask))\n",
    "print(\"any NaN in x:\", torch.isnan(x).any().item())\n",
    "print(\"any NaN in mask:\", torch.isnan(mask.float()).any().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = TimeSeriesDataset(train_ids, sensor=\"sentinel\",\n",
    "                           slice_mode=\"first_half\", transform=None)\n",
    "\n",
    "x_raw, _ = ds_raw[0]\n",
    "# x_raw is torch already in your implementation; if not, wrap torch.from_numpy\n",
    "print(\"raw x_raw any NaN:\", torch.isnan(x_raw).any().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dbbd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCEF(\n",
       "  (encoder): Encoder(\n",
       "    (0): ConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(63, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "        (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): ReLU()\n",
       "        (11): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): ConvBlock(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): ReLU()\n",
       "        (11): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (0): DeConvBlock(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): DeConvBlock(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): DeConvBlock(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): DeConvBlock(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample): Upsample(\n",
       "    (0): UpsampleBlock(\n",
       "      (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "    (1): UpsampleBlock(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "    (2): UpsampleBlock(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "    (3): UpsampleBlock(\n",
       "      (0): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.external.torchrs_fc_cd import FCEF\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# probe batch\n",
    "sample_x, _ = next(iter(train_loader))\n",
    "_, T, C, H, W = sample_x.shape\n",
    "\n",
    "model = FCEF(channels=C, t=T, num_classes=2).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17137b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits NaN: False\n",
      "single-batch loss: 0.6931473612785339\n"
     ]
    }
   ],
   "source": [
    "from src.models.external.torchrs_fc_cd import FCEF  # or your local file\n",
    "\n",
    "model1 = FCEF(channels=C, t=T, num_classes=2).to(device)  # C,T from a batch\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "x, mask = next(iter(train_loader))\n",
    "x = x.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model1(x)\n",
    "    print(\"logits NaN:\", torch.isnan(logits).any().item())\n",
    "    loss = criterion(logits, mask)\n",
    "    print(\"single-batch loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27bf5891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emma\\AppData\\Local\\Temp\\ipykernel_19272\\240919083.py:8: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  scaler = torch.amp.GradScaler(\"cuda\")\n",
      "epoch 1:   0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\emma\\Documents\\Land-Take-Prediction-Project-NINA-\\prosjekt_venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "epoch 1: 100%|██████████| 12/12 [00:09<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train=0.7436 val=0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 12/12 [00:09<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train=0.6651 val=0.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 12/12 [00:09<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train=0.6135 val=0.5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 12/12 [00:09<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train=0.5732 val=0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 12/12 [00:08<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train=0.5442 val=0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 12/12 [00:09<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train=0.5299 val=0.5219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 12/12 [00:09<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train=0.5208 val=0.5045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 12/12 [00:09<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: train=0.5069 val=0.4666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 12/12 [00:09<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: train=0.4988 val=0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 12/12 [00:10<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: train=0.4901 val=0.4528\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, mask in tqdm(train_loader, desc=f\"epoch {epoch+1}\"):\n",
    "        x = x.to(device)          # (B, T, C, H, W)\n",
    "        mask = mask.to(device)    # (B, H, W)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            logits = model(x)         # (B, 2, H, W)\n",
    "            loss = criterion(logits, mask)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, mask in val_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, mask)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"epoch {epoch+1}: train={avg_loss:.4f} val={val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ebad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosjekt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
